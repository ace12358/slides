e 辞書素性の追加
# 進捗報告20160407
## 小町研究室 M1 北川善彬

---
##春休みまとめ
* 年次大会 NLP2016
* IM研究会
* Chainer meet-up #2

* トヨタの成果物の納品
* B4のこのテーマ決め
* MicrosoftのインターンのためのCV書き
* 今後の方針の整理
* 朝倉くんのアノテーション

---
##年次大会コメント
* 今後どれをやれば精度が上がりそうですか？
    * bi(tri)-gram embedding、辞書素性
* BCCWJとTwitter に対する文字種素性の影響
    * データサイズによる影響
    * 1ポイントの重みが80付近、90付近で違う
* 中国語の論文の素性で日本語に効くようなものはなんでしたか？ 
    * 中国語は基本的に文字の embdedding のみですが、ラベルのtransition情報は使えるかも？

---
##グラムさんに質問
* KyTea の文字種、文字の window の違いはなんですか？
    * 文字と文字種のスパース度の違いからこうなっている、深層学習ならこの設定にとらわれることはないのでは？
* 辞書についても聞いたが、UniDicの辞書を使っていると言っていたが論文にはトレーニングデータから辞書を作ってるっぽい書き方をしている気がする

---
##IM研究会
* インプッドメソッドの研究会@京都大
* 全三日で後半2日間参加
* 一年計画くらいでインプッドを実装し、論文などを書けたらワークショップとかで書く？
####北川の担当
* 言語モデル担当
* 統計的IMには文字言語モデルと単語言語モデルが必要
* Perl で書かれたものを Python3 書き直し、文字コードはUTF-8にすること

---
##Chainer meetup #2
* 年次大会ベースで発表してきました
* ニコニコのコメント生成は面白そう
* 画像データを入力で出力言語でなんかやってた

---
トヨタの成果物の納品
* 2015年度の成果を整理
    * アノテーション
    * word-2vecベースの応答文選択システム
* README をかく

---
##B4の子のテーマ（提案）
* 形態素解析のための新語獲得の研究（仮）
    * 目的: NEologd のような辞書作成の補助になるような（半）自動獲得手法を考えること
    * 知識獲得、固有表現認識に近い
* データ: Web上のリソースで使えるもの
    * Twitter データ 
    * wikipedia

---

##今後の大雑把な方針の整理
* 学習の高速化
* bi-gram tri-gram embdedding, pre-training の利用
* transition の利用
* 辞書の利用
* CNN, bi-directional
* 品詞推定、読み推定

---
##transition の利用
* [Chen+ EMNLP2015]のモデルは結局、B → Iなどのラベル遷移の確率分布をだしているだけ
* なら、実際のコーパスを先になめて、P(B|I)などの確率分布を出しておいても良さそう？
* さらにP(B|あ,I)　みたいなのも計算できればよりリッチなのでは？
* 組み合わせ方は[Tsuboi EMNLP2014]も役に立つかも？

---
##辞書素性の利用
* ![Kobito.hqLQFm.png](https://qiita-image-store.s3.amazonaws.com/0/76221/2e42ef52-dfbe-acd2-85fc-706d04f6864b.png "Kobito.hqLQFm.png")
* l, r, i がそれぞれ binary 素性なので一番簡単なのは one-hot を作って embdedding にすること

---


##To do
* コードの書き直し（Chianer のverionアップ 1.4 → 1.7、高速化、）
* bi-gram tri-gram embedding の追加
* 辞書素性の利用
* pre-training アンサンブル？
* CNN、bi-directionalな手法

####単語分割の制度があがったら
* 品詞、読み推定、正規化

